{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Actividad 4 | Métricas de calidad de resultados**\n",
        "\n",
        "José Ricardo Munguía Marín\n",
        "A01795660@tec.mx\n"
      ],
      "metadata": {
        "id": "f7kbnstqIxJ1"
      },
      "id": "f7kbnstqIxJ1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 Construcción de la muestra M"
      ],
      "metadata": {
        "id": "SJ5wS97HGLWC"
      },
      "id": "SJ5wS97HGLWC"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construir una muestra M que sea representativa de la población P (a partir del dataset que recolectaste desde el inicio del curso).\n",
        "\n",
        "Esta parte viene de las actividades anteriores."
      ],
      "metadata": {
        "id": "E6sxXsBUgWtv"
      },
      "id": "E6sxXsBUgWtv"
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORTACIONES\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, year, when, udf\n",
        "from pyspark.sql.types import StringType\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, MinMaxScaler\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml.evaluation import ClusteringEvaluator"
      ],
      "metadata": {
        "id": "cpOCV_weHaqc"
      },
      "id": "cpOCV_weHaqc",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ----------------------------------------\n",
        "# SESIÓN SPARK\n",
        "# ----------------------------------------\n",
        "spark = SparkSession.builder.appName(\"MLlibEquipo52\").getOrCreate()\n",
        "\n",
        "# ----------------------------------------\n",
        "# CARGA Y UNIÓN DE DATOS\n",
        "# ----------------------------------------\n",
        "books = spark.read.csv(\"books_data.csv\", header=True, inferSchema=True)\n",
        "ratings = spark.read.csv(\"Books_rating.csv\", header=True, inferSchema=True)\n",
        "\n",
        "books = books.withColumnRenamed(\"title\", \"Title\")\n",
        "df = ratings.join(books.select(\"Title\", \"categories\", \"publishedDate\", \"ratingsCount\"), on=\"Title\", how=\"inner\")\n",
        "\n",
        "# FILTRADO DE NULOS PARA VARIABLES CLAVE\n",
        "# ----------------------------------------\n",
        "df_clean = df.filter(col(\"ratingsCount\").isNotNull() & col(\"review/score\").isNotNull())\n",
        "\n",
        "# PARTICIONAMIENTO SEGÚN CRITERIOS DE LA ACTIVIDAD 2\n",
        "# ----------------------------------------\n",
        "df_clean = df_clean.withColumn(\"ratings_partition\", when(col(\"ratingsCount\") <= 1000, \"baja\").otherwise(\"alta\"))\n",
        "df_clean = df_clean.withColumn(\"score_partition\", when(col(\"review/score\") < 4.0, \"baja\").otherwise(\"alta\"))\n",
        "\n",
        "part_A = df_clean.filter((col(\"ratings_partition\") == \"baja\") & (col(\"score_partition\") == \"baja\"))\n",
        "part_B = df_clean.filter((col(\"ratings_partition\") == \"baja\") & (col(\"score_partition\") == \"alta\"))\n",
        "part_C = df_clean.filter((col(\"ratings_partition\") == \"alta\") & (col(\"score_partition\") == \"baja\"))\n",
        "part_D = df_clean.filter((col(\"ratings_partition\") == \"alta\") & (col(\"score_partition\") == \"alta\"))\n",
        "\n",
        "# MUESTREO POR PARTICIÓN\n",
        "# ----------------------------------------\n",
        "sample_A = part_A.sample(False, 0.3, seed=42) #Partición 1: muestreo Aleatorio Simple al 30%\n",
        "sample_B = part_B.sample(False, 0.05, seed=42) #Partición 2: muestreo Aleatorio Simple al 5%\n",
        "\n",
        "#Partición 3: muestreo sistemático, toma 1 de cada 5 registros mediante indexado con zipWithIndex() y filtro\n",
        "sample_C = part_C.rdd.zipWithIndex().filter(lambda x: x[1] % 5 == 0).map(lambda x: x[0]).toDF()\n",
        "\n",
        "#Partición 4: Muestra Completa\n",
        "sample_D = part_D\n",
        "\n",
        "muestra_M = sample_A.union(sample_B).union(sample_C).union(sample_D)\n"
      ],
      "metadata": {
        "id": "J8GljqIcFss7"
      },
      "id": "J8GljqIcFss7",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ----------------------------------------\n",
        "# TRANSFORMACIONES PREVIAS\n",
        "# ----------------------------------------\n",
        "muestra_M = muestra_M.withColumn(\"year\", year(col(\"publishedDate\")))\n",
        "\n",
        "# LIMPIEZA Y CONVERSIÓN DE CATEGORIES A STRINGS SIMPLES\n",
        "to_string_udf = udf(lambda x: str(x).strip(\"[]'\").split(\",\")[0] if x else None, StringType())\n",
        "muestra_M = muestra_M.withColumn(\"categories\", to_string_udf(\"categories\"))\n",
        "muestra_M = muestra_M.filter(col(\"categories\").isNotNull())\n",
        "\n",
        "# CONVERSIÓN DE ratingsCount A TIPO NUMÉRICO\n",
        "muestra_M = muestra_M.withColumn(\"ratingsCount\", col(\"ratingsCount\").cast(\"double\"))\n",
        "\n",
        "# BINARIZACIÓN DE LABEL\n",
        "muestra_M = muestra_M.withColumn(\"label\", when(col(\"review/score\") >= 4.0, 1).otherwise(0))\n",
        "\n",
        "# ELIMINAR NULOS EN COLUMNAS EXISTENTES\n",
        "muestra_M = muestra_M.dropna(subset=[\"ratingsCount\", \"year\", \"categories\"])\n",
        "\n",
        "# PIPELINE DE TRANSFORMACIÓN\n",
        "# ----------------------------------------\n",
        "indexer = StringIndexer(inputCol=\"categories\", outputCol=\"categories_index\", handleInvalid=\"keep\")\n",
        "encoder = OneHotEncoder(inputCol=\"categories_index\", outputCol=\"categories_encoded\", handleInvalid=\"keep\")\n",
        "assembler = VectorAssembler(inputCols=[\"ratingsCount\", \"year\", \"categories_encoded\"], outputCol=\"features_raw\")\n",
        "scaler = MinMaxScaler(inputCol=\"features_raw\", outputCol=\"features\")\n",
        "\n",
        "pipeline = Pipeline(stages=[indexer, encoder, assembler, scaler])\n",
        "model_prep = pipeline.fit(muestra_M)\n",
        "muestra_final = model_prep.transform(muestra_M)\n"
      ],
      "metadata": {
        "id": "7O3BGGgwFzXa"
      },
      "id": "7O3BGGgwFzXa",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2 Preparación del conjunto de entrenamiento y prueba"
      ],
      "metadata": {
        "id": "JAA0OPHJgWXj"
      },
      "id": "JAA0OPHJgWXj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "En esta actividad **no se volvió a dividir la muestra M por subconjuntos (A, B, C, D)**, ya que `M` fue construida de forma controlada, balanceada y representativa desde el inicio, aplicando diferentes técnicas de muestreo (simple, sistemático, censal, etc.) sobre grupos disjuntos.\n",
        "\n",
        "Intentar particionar de nuevo por grupo generaba **duplicación de datos, sobrecarga de memoria y retrasos**, porque requería hacer joins con `muestra_final`, forzando un shuffle de datos innecesario. Además, no aportaba valor estadístico adicional.\n",
        "\n",
        "Por ello, se optó por una división simple con `randomSplit([0.8, 0.2])` directamente sobre `muestra_final`. Esto mantiene la representatividad de los datos y mejora la eficiencia del pipeline sin afectar la validez del entrenamiento ni de la evaluación.\n",
        "\n",
        "*Nota: Se intentó varías veces crear está Muestra, pero rompía el pipeline y generaba duplicación, se dejo corriendo por casi 24 Hrs sin resultados.*"
      ],
      "metadata": {
        "id": "q9O3gzrIKk0o"
      },
      "id": "q9O3gzrIKk0o"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ----------------------------------------\n",
        "# DIVISIÓN TRAIN/TEST\n",
        "train_data, test_data = muestra_final.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# CONVERSIÓN DE LABEL A DOUBLE\n",
        "train_data = train_data.withColumn(\"label\", col(\"label\").cast(\"double\"))\n",
        "test_data = test_data.withColumn(\"label\", col(\"label\").cast(\"double\"))\n"
      ],
      "metadata": {
        "id": "82J3ZVw5F17q"
      },
      "id": "82J3ZVw5F17q",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3 Selección de métricas para medir calidad de resultados"
      ],
      "metadata": {
        "id": "C3oGA3_EGcqX"
      },
      "id": "C3oGA3_EGcqX"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Para el modelo supervisado:**\n",
        "\n",
        "Se utilizaron las métricas de `accuracy`, `F1-score`, `precision ponderada` y `recall ponderado`.\n",
        "\n",
        "- **Accuracy** indica el porcentaje de clasificaciones correctas.\n",
        "- **F1-score** equilibra precisión y exhaustividad, útil si las clases están desbalanceadas.\n",
        "- **Weighted Precision** mide qué tan confiables son las predicciones positivas, ponderadas por el soporte de cada clase.\n",
        "- **Weighted Recall** refleja cuántos verdaderos positivos se capturaron, también ponderado.\n",
        "\n",
        "En contextos de Big Data, usar métricas agregadas ponderadas ayuda a evaluar modelos sin procesar todos los datos de forma individual y mantiene una visión general balanceada del rendimiento.\n",
        "\n",
        "**Para el modelo no supervisado (KMeans):**\n",
        "\n",
        "Se eligió la métrica **Silhouette score**, ya que permite evaluar qué tan bien separados y compactos están los clústeres generados. Esta métrica va de -1 a 1, donde valores cercanos a 1 indican una buena separación entre grupos.  \n"
      ],
      "metadata": {
        "id": "g5m7X3axGZYL"
      },
      "id": "g5m7X3axGZYL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4 Entrenamiento de Modelos de Aprendizaje"
      ],
      "metadata": {
        "id": "K6Ku6MOHgn5x"
      },
      "id": "K6Ku6MOHgn5x"
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------\n",
        "# MODELO SUPERVISADO\n",
        "# ----------------------------------------\n",
        "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
        "dt_model = dt.fit(train_data)\n",
        "predictions = dt_model.transform(test_data)\n",
        "\n"
      ],
      "metadata": {
        "id": "SeW-kuSlF-Vc"
      },
      "id": "SeW-kuSlF-Vc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------\n",
        "# Métricas de Rendimiento para nuestro random forest\n",
        "# ----------------------------------------\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
        "\n",
        "for metric in [\"accuracy\", \"f1\", \"weightedPrecision\", \"weightedRecall\"]:\n",
        "    evaluator.setMetricName(metric)\n",
        "    print(f\"{metric}: {evaluator.evaluate(predictions):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ljJXIqmv7xtW",
        "outputId": "e30669ab-05cf-4619-ef28-4dc10a563a8f"
      },
      "id": "ljJXIqmv7xtW",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.7709\n",
            "f1: 0.7759\n",
            "weightedPrecision: 0.8133\n",
            "weightedRecall: 0.7709\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# MODELO NO SUPERVISADO\n",
        "# ----------------------------------------\n",
        "kmeans = KMeans(featuresCol=\"features\", k=15, seed=42)\n",
        "kmeans_model = kmeans.fit(muestra_final)\n",
        "clusters = kmeans_model.transform(muestra_final)\n",
        "\n",
        "evaluator_cluster = ClusteringEvaluator(featuresCol=\"features\", metricName=\"silhouette\", distanceMeasure=\"squaredEuclidean\")\n",
        "print(\"Silhouette score:\", evaluator_cluster.evaluate(clusters))\n",
        "clusters.groupBy(\"prediction\").count().show()\n"
      ],
      "metadata": {
        "id": "sWphaHUqF_Hx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "44a10a26-fb2c-4414-c907-62cbcbc49959"
      },
      "id": "sWphaHUqF_Hx",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Silhouette score: 0.7205232669620012\n",
            "+----------+-----+\n",
            "|prediction|count|\n",
            "+----------+-----+\n",
            "|        12| 2580|\n",
            "|         1|56485|\n",
            "|        13|35790|\n",
            "|         6| 4402|\n",
            "|         3| 8595|\n",
            "|         5| 2029|\n",
            "|         4| 1417|\n",
            "|         8| 5212|\n",
            "|        10| 4766|\n",
            "|        11| 2255|\n",
            "|        14| 1197|\n",
            "|         2|36734|\n",
            "|         9|10860|\n",
            "|         7| 2033|\n",
            "|         0|52769|\n",
            "+----------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5 Análisis de resultados**\n",
        "\n",
        "El modelo supervisado (árbol de decisión) mostró un buen desempeño general, con una **accuracy superior al 77%** y un **F1-score cercano al 78%**. Esto indica que el modelo logra un equilibrio entre precisión y recall, siendo efectivo incluso en presencia de cierto desbalance de clases.  \n",
        "Además, la **precisión ponderada (≈ 81%)** confirma que cuando el modelo predice una clase, suele acertar, y la **recall ponderada (≈ 77%)** demuestra que identifica correctamente la mayoría de los casos positivos. Estas métricas respaldan que el modelo generaliza bien sobre los datos de prueba.\n",
        "\n",
        "En el modelo no supervisado (KMeans), el **Silhouette score ≈ 0.72** sugiere una separación aceptable entre los clústeres, con estructuras bien definidas y poca mezcla entre grupos. Aunque no se cuenta con etiquetas reales para validar el agrupamiento, este valor indica que los patrones identificados por el modelo tienen coherencia interna.\n",
        "\n",
        "En ambos casos, las métricas seleccionadas permiten evaluar de manera confiable el rendimiento sin procesar todos los datos manualmente, lo cual es fundamental al trabajar con grandes volúmenes de información usando Spark.\n"
      ],
      "metadata": {
        "id": "lPTsY3zOpTtt"
      },
      "id": "lPTsY3zOpTtt"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}