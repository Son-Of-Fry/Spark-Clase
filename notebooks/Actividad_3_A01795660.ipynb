{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Actividad 3 - modelos supervizados y no supervizados**\n",
        "\n",
        "José Ricardo Munguía Marín\n",
        "A01795660@tec.mx\n"
      ],
      "metadata": {
        "id": "f7kbnstqIxJ1"
      },
      "id": "f7kbnstqIxJ1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 Introducción Teórica"
      ],
      "metadata": {
        "id": "pIskdeMwgOOh"
      },
      "id": "pIskdeMwgOOh"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aprendizaje supervisado vs no supervisado\n",
        "\n",
        "El aprendizaje supervisado es un enfoque de machine learning donde el modelo se entrena con datos etiquetados, es decir, con ejemplos cuya respuesta correcta ya se conoce. Muy parecido al concepto de Regresiones Lineales.\n",
        "\n",
        "\n",
        "El objetivo es que el modelo aprenda la relación entre las características de entrada y el resultado, para luego poder predecir correctamente las etiquetas de nuevos datos.\n",
        "\n",
        "Un caso típico de aprendizaje supervisado con aplicación a nuestro proyecto es los de tipo clasificación, donde se entrena un modelo para distinguir categorías (por ejemplo, reseñas positivas vs reseñas negativas), utilizando ejemplos previamente categorizados como positivos o negativos.\n",
        "\n",
        "\n",
        "En nuestro proyecto,contamos con reseñas de libros y sabemos si su calificación (score) indica una percepción positiva o negativa de la calidad; con esos datos entrenamos un modelo que pueda predecir el sentimiento de una reseña nueva.\n",
        "\n",
        "Por otro lado, el aprendizaje no supervisado se utiliza cuando no disponemos de etiquetas o categorías predefinidas en los datos. En lugar de predecir un valor objetivo conocido, el modelo intenta descubrir patrones o estructuras ocultas por sí mismo.\n",
        "\n",
        "Un ejemplo común que vamos a aplicar es el agrupamiento (clustering), donde el algoritmo organiza los datos en grupos basándose en su similitud, sin que nadie le haya dicho de antemano cuáles son esos grupos.\n",
        "\n",
        "\n",
        "###Modelo DecisionTreeClassifier para clasificar reseñas\n",
        "\n",
        "Para la tarea de clasificación de reseñas (aprendizaje supervisado), decidimos usar un árbol de decisión mediante la clase DecisionTreeClassifier de PySpark.\n",
        "\n",
        "Un árbol de decisión es un modelo de clasificación que aprende a tomar decisiones basadas en una serie de preguntas sobre las características de los datos, organizadas en forma de árbol. Elegimos este modelo por varias razones:\n",
        "\n",
        "1. Interpretabilidad: Los árboles de decisión son fáciles de interpretar gracias a que las predicciones se realizan siguiendo ramas lógicas if/then. Esto significa que podemos entender por qué el modelo clasificó una reseña como positiva o negativa al seguir las reglas del árbol. Esta claridad será muy útil para analizar resultados posteriormente cuando un producto de ML es entregado.\n",
        "\n",
        "2. Manejo de variables heterogéneas: El DecisionTreeClassifier puede trabajar con características numéricas como categóricas sin necesidad de mucho procesamiento adicional.\n",
        "\n",
        "3. Sencillez y eficacia en clasificación binaria: Para distinguir reseñas positivas vs negativas (por ejemplo, podríamos definir positiva si la calificación del usuario es ≥ 4 estrellas, caso contrario negativa).\n",
        "\n",
        "En resumen, el DecisionTreeClassifier parece adecuado para empezar a experimentar pues provee un buen balance entre interpretabilidad y rendimiento para la clasificación de reseñas en positivas o negativas.\n",
        "\n",
        "\n",
        "###Modelo KMeans para agrupar libros\n",
        "\n",
        "Para la tarea de agrupamiento de libros según popularidad y antigüedad (aprendizaje no supervisado), utilizamos el algoritmo K-Means mediante la clase KMeans de PySpark.\n",
        "\n",
        "La idea es pedirle al algoritmo que divida nuestros libros en K grupos distintos, donde K es un número que definimos (por ejemplo, 3, 5, 10, etc.), de forma que los libros dentro de cada grupo sean lo más similares posible entre sí en términos de variables.\n",
        "\n",
        "Elegimos K-Means principalmente porque:\n",
        "1. Simplicidad y eficiencia: K-Means es fácil de entender e implementar, y suele converger rápidamente. Esto lo hace práctico para explorar agrupaciones iniciales en un conjunto de datos grande. Encaja bien con nuestro dataset de reseñas de Amazon (que contiene millones de registros). Usando PySpark, podemos aprovechar K-Means para procesar muchos libros en paralelo sin demasiada complicación en el código.\n",
        "\n",
        "- Resultados interpretables: da centroides para cada clúster, que básicamente representan el libro “promedio” en términos de popularidad y antigüedad en ese grupo.\n",
        "\n",
        "-\tNo requiere etiqueta previa: Dado que no teníamos una variable objetiva para este análisis (no hay una clasificación preexistente de libros por categorías de popularidad/antigüedad), K-Means era una opción natural.\n",
        "\n",
        "Vamos a usar K-Means porque queríamos explorar la estructura de la base de datos de libros en términos de popularidad y antigüedad."
      ],
      "metadata": {
        "id": "oPip7bsggWzJ"
      },
      "id": "oPip7bsggWzJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 Selección de Datos"
      ],
      "metadata": {
        "id": "4-nldd9ngWwY"
      },
      "id": "4-nldd9ngWwY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Partimos de una muestra representativa de las reseñas de Amazon Book Reviews (llamada muestra M en el notebook).\n",
        "Ahora, para poder craer esta muestra M, se crearon primero las particiones correspondientes para crearla. Estás particiones fueron creadas en la cartividad anterior, para asegurar un muestreo representativo basado en cada tipo de variable.\n"
      ],
      "metadata": {
        "id": "E6sxXsBUgWtv"
      },
      "id": "E6sxXsBUgWtv"
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "# IMPORTACIONES\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, year, when, udf\n",
        "from pyspark.sql.types import StringType\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, MinMaxScaler\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml.evaluation import ClusteringEvaluator"
      ],
      "metadata": {
        "id": "cpOCV_weHaqc"
      },
      "id": "cpOCV_weHaqc",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ----------------------------------------\n",
        "# SESIÓN SPARK\n",
        "# ----------------------------------------\n",
        "spark = SparkSession.builder.appName(\"MLlibEquipo52\").getOrCreate()\n",
        "\n",
        "# ----------------------------------------\n",
        "# PARTE 2: Selección de los datos\n",
        "# CARGA Y UNIÓN DE DATOS\n",
        "# ----------------------------------------\n",
        "books = spark.read.csv(\"books_data.csv\", header=True, inferSchema=True)\n",
        "ratings = spark.read.csv(\"Books_rating.csv\", header=True, inferSchema=True)\n",
        "\n",
        "books = books.withColumnRenamed(\"title\", \"Title\")\n",
        "df = ratings.join(books.select(\"Title\", \"categories\", \"publishedDate\", \"ratingsCount\"), on=\"Title\", how=\"inner\")\n",
        "\n",
        "# FILTRADO DE NULOS PARA VARIABLES CLAVE\n",
        "# ----------------------------------------\n",
        "df_clean = df.filter(col(\"ratingsCount\").isNotNull() & col(\"review/score\").isNotNull())\n",
        "\n",
        "# PARTICIONAMIENTO SEGÚN CRITERIOS DE LA ACTIVIDAD 2\n",
        "# ----------------------------------------\n",
        "df_clean = df_clean.withColumn(\"ratings_partition\", when(col(\"ratingsCount\") <= 1000, \"baja\").otherwise(\"alta\"))\n",
        "df_clean = df_clean.withColumn(\"score_partition\", when(col(\"review/score\") < 4.0, \"baja\").otherwise(\"alta\"))\n",
        "\n",
        "part_A = df_clean.filter((col(\"ratings_partition\") == \"baja\") & (col(\"score_partition\") == \"baja\"))\n",
        "part_B = df_clean.filter((col(\"ratings_partition\") == \"baja\") & (col(\"score_partition\") == \"alta\"))\n",
        "part_C = df_clean.filter((col(\"ratings_partition\") == \"alta\") & (col(\"score_partition\") == \"baja\"))\n",
        "part_D = df_clean.filter((col(\"ratings_partition\") == \"alta\") & (col(\"score_partition\") == \"alta\"))\n",
        "\n",
        "# MUESTREO POR PARTICIÓN\n",
        "# ----------------------------------------\n",
        "sample_A = part_A.sample(False, 0.3, seed=42) #Partición 1: muestreo Aleatorio Simple al 30%\n",
        "sample_B = part_B.sample(False, 0.05, seed=42) #Partición 2: muestreo Aleatorio Simple al 5%\n",
        "\n",
        "#Partición 3: muestreo sistemático, toma 1 de cada 5 registros mediante indexado con zipWithIndex() y filtro\n",
        "sample_C = part_C.rdd.zipWithIndex().filter(lambda x: x[1] % 5 == 0).map(lambda x: x[0]).toDF()\n",
        "\n",
        "#Partición 4: Muestra Completa\n",
        "sample_D = part_D\n",
        "\n",
        "muestra_M = sample_A.union(sample_B).union(sample_C).union(sample_D)\n"
      ],
      "metadata": {
        "id": "J8GljqIcFss7"
      },
      "id": "J8GljqIcFss7",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 Preparción de Datos"
      ],
      "metadata": {
        "id": "W8BBaXtlgbzA"
      },
      "id": "W8BBaXtlgbzA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antes de modelar, realizamos limpieza básica. Esto incluyó eliminar filas con valores nulos o incompletos que pudieran afectar el entrenamiento (por ejemplo, libros sin fecha de publicación o reseñas sin puntuación).\n",
        "\n",
        "También convertimos tipos de datos cuando fue necesario por ejemplo, asegurándonos de que el campo de número de calificaciones (ratingsCount) estuviera en formato numérico y no como texto.\n",
        "\n",
        "\n",
        "####Transformación y feature engineering:\n",
        "\n",
        "Esta es una etapa clave donde preparamos las variables de entrada para los modelos:\n",
        "- **Codificación de categóricas**\n",
        "- **Extracción de características numéricas**\n",
        "\n",
        "Pero las más importantes fueron:\n",
        "\n",
        "- **Binarización de la variable objetivo**: Para el modelo supervisado, definimos la etiqueta label indicando percepción positiva o negativa de la reseña. Se consideró positiva (label = 1) si la calificación de la reseña era ≥ 4.0 (asumiendo que las calificaciones son de 1 a 5 estrellas), y negativa (label = 0) si era menor a 4.0. De este modo convertimos el problema en una clasificación binaria simple. Esto fue más sugestivo, no quiere decir que los otros libros fueran malos.\n",
        "\n",
        "- **Ensamblaje de features:** Con las características preparadas (por ejemplo: categoría codificada, año de publicación, número de reseñas, posiblemente otras como la puntuación promedio, etc.), las combinamos en una única columna de features utilizando VectorAssembler de PySpark. Esto nos da un vector numérico por cada libro/reseña, que representa todas las variables predictoras.\n",
        "\n",
        "- Norma**lización (escalado)**: Para el algoritmo KMeans en particular, es recomendable normalizar las características numéricas, ya que este algoritmo basa sus agrupaciones en distancias. En nuestro caso, la escala de antigüedad (por año) y la de popularidad (por número de reseñas, que puede ir de decenas a miles) son muy diferentes."
      ],
      "metadata": {
        "id": "ub7eiWxtgWrc"
      },
      "id": "ub7eiWxtgWrc"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ----------------------------------------\n",
        "# PARTE 3: Preparación de los datos\n",
        "# TRANSFORMACIONES PREVIAS\n",
        "# ----------------------------------------\n",
        "muestra_M = muestra_M.withColumn(\"year\", year(col(\"publishedDate\")))\n",
        "\n",
        "# LIMPIEZA Y CONVERSIÓN DE CATEGORIES A STRINGS SIMPLES\n",
        "to_string_udf = udf(lambda x: str(x).strip(\"[]'\").split(\",\")[0] if x else None, StringType())\n",
        "muestra_M = muestra_M.withColumn(\"categories\", to_string_udf(\"categories\"))\n",
        "muestra_M = muestra_M.filter(col(\"categories\").isNotNull())\n",
        "\n",
        "# CONVERSIÓN DE ratingsCount A TIPO NUMÉRICO\n",
        "muestra_M = muestra_M.withColumn(\"ratingsCount\", col(\"ratingsCount\").cast(\"double\"))\n",
        "\n",
        "# BINARIZACIÓN DE LABEL\n",
        "muestra_M = muestra_M.withColumn(\"label\", when(col(\"review/score\") >= 4.0, 1).otherwise(0))\n",
        "\n",
        "# ELIMINAR NULOS EN COLUMNAS EXISTENTES\n",
        "muestra_M = muestra_M.dropna(subset=[\"ratingsCount\", \"year\", \"categories\"])\n",
        "\n",
        "# PIPELINE DE TRANSFORMACIÓN\n",
        "# ----------------------------------------\n",
        "indexer = StringIndexer(inputCol=\"categories\", outputCol=\"categories_index\", handleInvalid=\"keep\")\n",
        "encoder = OneHotEncoder(inputCol=\"categories_index\", outputCol=\"categories_encoded\", handleInvalid=\"keep\")\n",
        "assembler = VectorAssembler(inputCols=[\"ratingsCount\", \"year\", \"categories_encoded\"], outputCol=\"features_raw\")\n",
        "scaler = MinMaxScaler(inputCol=\"features_raw\", outputCol=\"features\")\n",
        "\n",
        "pipeline = Pipeline(stages=[indexer, encoder, assembler, scaler])\n",
        "model_prep = pipeline.fit(muestra_M)\n",
        "muestra_final = model_prep.transform(muestra_M)\n"
      ],
      "metadata": {
        "id": "7O3BGGgwFzXa"
      },
      "id": "7O3BGGgwFzXa",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4 Preparación del conjunto de entrenamiento y Prueba"
      ],
      "metadata": {
        "id": "JAA0OPHJgWXj"
      },
      "id": "JAA0OPHJgWXj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Para el modelo supervisado (Decision Tree)**, Dividimos la muestra de datos en un conjunto de entrenamiento (train) y otro de prueba (test). Esta separación nos permite luego evaluar qué tan bien generaliza el modelo a datos no vistos.\n",
        "\n",
        "\n",
        "**Para el modelo no supervisado (KMeans)**, No necesitamos una división train/test de la misma forma, ya que el objetivo no es predecir etiquetas conocidas sino agrupar todo el conjunto. Así que tomamos el conjunto completo de datos procesados (muestra_final) .En el código final, por ejemplo, probamos con **K=15** para formar diez grupos de libros, pues son muchas las categorias que existen.\n"
      ],
      "metadata": {
        "id": "Wu9fCURYoZJO"
      },
      "id": "Wu9fCURYoZJO"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ----------------------------------------\n",
        "# PARTE 4: Preparación del conjunto de entrenamiento y prueba\n",
        "# DIVISIÓN TRAIN/TEST\n",
        "train_data, test_data = muestra_final.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# CONVERSIÓN DE LABEL A DOUBLE\n",
        "train_data = train_data.withColumn(\"label\", col(\"label\").cast(\"double\"))\n",
        "test_data = test_data.withColumn(\"label\", col(\"label\").cast(\"double\"))\n"
      ],
      "metadata": {
        "id": "82J3ZVw5F17q"
      },
      "id": "82J3ZVw5F17q",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Construcción de modelos de aprendizaje supervisado y no supervisado"
      ],
      "metadata": {
        "id": "K6Ku6MOHgn5x"
      },
      "id": "K6Ku6MOHgn5x"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ----------------------------------------\n",
        "# PARTE 5: Construcción de modelos de aprendizaje supervisado y no supervisado\n",
        "# MODELO SUPERVISADO\n",
        "# ----------------------------------------\n",
        "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
        "dt_model = dt.fit(train_data)\n",
        "predictions = dt_model.transform(test_data)\n",
        "\n",
        "evaluator_acc = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "\n",
        "print(\"Accuracy:\", evaluator_acc.evaluate(predictions))\n",
        "print(\"F1-score:\", evaluator_f1.evaluate(predictions))"
      ],
      "metadata": {
        "id": "SeW-kuSlF-Vc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d0f87b2-4ea8-43f5-d230-a0d6cfccd748"
      },
      "id": "SeW-kuSlF-Vc",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7153083700440529\n",
            "F1-score: 0.7111588248537959\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# MODELO NO SUPERVISADO\n",
        "# ----------------------------------------\n",
        "kmeans = KMeans(featuresCol=\"features\", k=15, seed=42)\n",
        "kmeans_model = kmeans.fit(muestra_final)\n",
        "clusters = kmeans_model.transform(muestra_final)\n",
        "\n",
        "evaluator_cluster = ClusteringEvaluator(featuresCol=\"features\", metricName=\"silhouette\", distanceMeasure=\"squaredEuclidean\")\n",
        "print(\"Silhouette score:\", evaluator_cluster.evaluate(clusters))\n",
        "clusters.groupBy(\"prediction\").count().show()\n"
      ],
      "metadata": {
        "id": "sWphaHUqF_Hx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42296e14-df5a-4fa1-aec6-77391d6fe772"
      },
      "id": "sWphaHUqF_Hx",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Silhouette score: 0.7170509886949381\n",
            "+----------+-----+\n",
            "|prediction|count|\n",
            "+----------+-----+\n",
            "|        12|  270|\n",
            "|         1|  355|\n",
            "|        13|  662|\n",
            "|         6| 8037|\n",
            "|         5|  398|\n",
            "|         9|  762|\n",
            "|         4| 5902|\n",
            "|         8|  183|\n",
            "|        10|  737|\n",
            "|        11|  423|\n",
            "|        14|  727|\n",
            "|         0| 2487|\n",
            "|         7|  519|\n",
            "|         2| 4892|\n",
            "|         3| 1380|\n",
            "+----------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusión**\n",
        "\n",
        "Podemos comparar el desempeño y utilidad de cada modelo en el contexto de las reseñas de libros de Amazon con Spark:\n",
        "\n",
        "DecisionTreeClassifier (Supervisado): El árbol de decisión logró una precisión alrededor del 71% (accuracy ≈ 0.715) al clasificar las reseñas en positivas o negativas, junto con un F1-score aproximado de 0.711 en el conjunto de prueba.\n",
        "\n",
        "\n",
        "KMeans (No supervisado): Al agrupar los libros mediante KMeans, en la configuración final usamos K = 15 clústeres, obteniendo un índice de silueta alrededor de 0.71. Un Silhouette score de 0.71 indica una cohesión de clúster moderadamente alta: los libros en general están bien agrupados con otros similares, aunque podría haber algo de solapamiento entre ciertos grupos.\n",
        "\n",
        "Pero, hablando sobre Spark y las particiones. al generar una muestra representativa con lo que se analizó previamente ayudo bastante a reducir la carga que llegaría a tener un modelo implementado con otras librerias como SKlearn. Los tiempos para procesar casi 3 GB de data fueron excelentes."
      ],
      "metadata": {
        "id": "lPTsY3zOpTtt"
      },
      "id": "lPTsY3zOpTtt"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}